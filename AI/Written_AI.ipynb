{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Self written AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import PIL\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.3, 0.3, 0.3), (0.3,0.3,0.3))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcess():\n",
    "    def __init__(self, label_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(label_file, header=None)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = PIL.Image.open(img_path)\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=DataProcess(label_file=\"./dataset/default/labels/TRAIN.csv\",img_dir=\"./dataset/default/TRAIN/\",transform=transform)\n",
    "test_data=DataProcess(label_file=\"./dataset/default/labels/TEST.csv\",img_dir=\"./dataset/default/TEST/\",transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 320, 479])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image,label=train_data[0]\n",
    "image.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader= torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True, num_workers=0)\n",
    "test_loader= torch.utils.data.DataLoader(test_data, batch_size=32, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "    self.conv1= nn.Conv2d(3, 30, 20) # (50, 300, 459) ((320-20)/5)+1 = 28\n",
    "    self.pool= nn.MaxPool2d(4, 4) # (50, 150, 229)\n",
    "    self.conv2 = nn.Conv2d(30, 60, 60) #(30, 120, 199) => (30, 60, 99.5)\n",
    "    self.fc1 = nn.Linear(3360, 1600)\n",
    "    self.fc2 = nn.Linear(1600, 800)\n",
    "    self.fc3 = nn.Linear(800, 8)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.pool(F.relu(self.conv1(x)))\n",
    "    x = self.pool(F.relu(self.conv2(x)))\n",
    "    x = torch.flatten(x, 1)\n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = F.relu(self.fc2(x))\n",
    "    x = self.fc3(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetV2(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "    self.conv1= nn.Conv2d(3, 15, 20) # (50, 300, 459) ((320-20)/5)+1 = 28\n",
    "    self.pool= nn.MaxPool2d(2, 2) # (50, 150, 229)\n",
    "    self.pool2= nn.MaxPool2d(5, 5) # (50, 150, 229)\n",
    "    self.conv2 = nn.Conv2d(15, 30, 30) #(30, 120, 199) => (30, 60, 99.5)\n",
    "    self.conv3 = nn.Conv2d(30, 60, 30) #(60, 30, 69.5) => (60, 15, 35)\n",
    "    self.fc1 = nn.Linear(5040, 1600)\n",
    "    self.fc2 = nn.Linear(1600, 800)\n",
    "    self.fc3 = nn.Linear(800, 8)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.pool(F.relu(self.conv1(x)))\n",
    "    x = self.pool(F.relu(self.conv2(x)))\n",
    "    x = self.pool2(F.relu(self.conv3(x)))\n",
    "    x = torch.flatten(x, 1)\n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = F.relu(self.fc2(x))\n",
    "    x = self.fc3(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetV3(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "    self.conv1= nn.Conv2d(3, 15, 20) # (50, 300, 459) ((320-20)/5)+1 = 28\n",
    "    self.pool= nn.MaxPool2d(2, 2) # (50, 150, 229)\n",
    "    self.pool2= nn.MaxPool2d(5, 5) # (50, 150, 229)\n",
    "    self.conv2 = nn.Conv2d(15, 30, 30) #(30, 120, 199) => (30, 60, 99.5)\n",
    "    self.conv3 = nn.Conv2d(30, 60, 30) #(60, 30, 69.5) => (60, 15, 35)\n",
    "    self.fc1 = nn.Linear(5040, 2000)\n",
    "    self.fc2 = nn.Linear(2000, 8)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.pool(F.relu(self.conv1(x)))\n",
    "    x = self.pool(F.relu(self.conv2(x)))\n",
    "    x = self.pool2(F.relu(self.conv3(x)))\n",
    "    x = torch.flatten(x, 1)\n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = self.fc2(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NeuralNetV3()\n",
    "net.to(device=device)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.003, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(best):\n",
    "    test=NeuralNetV3()\n",
    "    test.to(device)\n",
    "    test.load_state_dict(torch.load(\"./models/self_train/default_last_3_0.pt\", weights_only=True))\n",
    "    test.eval()\n",
    "    total=0\n",
    "    correct=0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(test_loader):\n",
    "            images_test, labels_test = data\n",
    "            images_test, labels_test = images_test.to(device), labels_test.to(device)\n",
    "            outputs=test(images_test)\n",
    "            _, predicts = torch.max(outputs, 1)\n",
    "\n",
    "            total += labels_test.size(0)\n",
    "\n",
    "            correct += (predicts==labels_test).sum().item()\n",
    "        \n",
    "        accuracy = 100*correct/total\n",
    "        \n",
    "        if best < accuracy:\n",
    "            torch.save(test.state_dict(), \"./models/self_train/default_best_3_0.pt\")\n",
    "        \n",
    "        print(f'Accuracy: {accuracy}%')\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train():\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = net(inputs)\n",
    "        # print(output[0].size())\n",
    "        loss = loss_function(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    running_loss += loss.item()\n",
    "\n",
    "    print(f'Loss: {running_loss / len(train_loader): .4f}')\n",
    "\n",
    "    torch.save(net.state_dict(), \"./models/self_train/default_last_3_0.pt\")\n",
    "   \n",
    "   \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([14280])\n",
      "torch.Size([14280])\n",
      "torch.Size([14280])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[19], line 5\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[0;32m      4\u001b[0m     inputs, labels \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m----> 5\u001b[0m     inputs, labels \u001b[38;5;241m=\u001b[39m \u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m, labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      6\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m      7\u001b[0m     output \u001b[38;5;241m=\u001b[39m net(inputs)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 0...\n",
      "Loss:  0.0159\n",
      "Accuracy: 38.42165898617512%\n",
      "Training epoch 1...\n",
      "Loss:  0.0086\n",
      "Accuracy: 46.71658986175115%\n",
      "Training epoch 2...\n",
      "Loss:  0.0292\n",
      "Accuracy: 60.19585253456221%\n",
      "Training epoch 3...\n",
      "Loss:  0.0015\n",
      "Accuracy: 72.1774193548387%\n",
      "Training epoch 4...\n",
      "Loss:  0.0086\n",
      "Accuracy: 68.37557603686636%\n",
      "Training epoch 5...\n",
      "Loss:  0.0037\n",
      "Accuracy: 77.76497695852535%\n",
      "Training epoch 6...\n",
      "Loss:  0.0000\n",
      "Accuracy: 77.47695852534562%\n",
      "Training epoch 7...\n",
      "Loss:  0.0003\n",
      "Accuracy: 82.25806451612904%\n",
      "Training epoch 8...\n",
      "Loss:  0.0000\n",
      "Accuracy: 81.27880184331798%\n",
      "Training epoch 9...\n",
      "Loss:  0.0000\n",
      "Accuracy: 86.00230414746544%\n",
      "Training epoch 10...\n",
      "Loss:  0.0000\n",
      "Accuracy: 84.44700460829493%\n",
      "Training epoch 11...\n",
      "Loss:  0.0000\n",
      "Accuracy: 86.52073732718894%\n",
      "Training epoch 12...\n",
      "Loss:  0.0000\n",
      "Accuracy: 86.29032258064517%\n",
      "Training epoch 13...\n",
      "Loss:  0.0000\n",
      "Accuracy: 86.63594470046083%\n",
      "Training epoch 14...\n",
      "Loss:  0.0000\n",
      "Accuracy: 84.21658986175115%\n",
      "Training epoch 15...\n",
      "Loss:  0.0000\n",
      "Accuracy: 86.00230414746544%\n",
      "Training epoch 16...\n",
      "Loss:  0.0000\n",
      "Accuracy: 87.84562211981567%\n",
      "Training epoch 17...\n",
      "Loss:  0.0000\n",
      "Accuracy: 89.17050691244239%\n",
      "Training epoch 18...\n",
      "Loss:  0.0000\n",
      "Accuracy: 89.17050691244239%\n",
      "Training epoch 19...\n",
      "Loss:  0.0000\n",
      "Accuracy: 89.17050691244239%\n",
      "Training epoch 20...\n",
      "Loss:  0.0000\n",
      "Accuracy: 89.22811059907833%\n",
      "Training epoch 21...\n",
      "Loss:  0.0000\n",
      "Accuracy: 89.34331797235023%\n",
      "Training epoch 22...\n",
      "Loss:  0.0000\n",
      "Accuracy: 89.40092165898618%\n",
      "Training epoch 23...\n",
      "Loss:  0.0000\n",
      "Accuracy: 89.34331797235023%\n",
      "Training epoch 24...\n",
      "Loss:  0.0000\n",
      "Accuracy: 89.34331797235023%\n",
      "Training epoch 25...\n",
      "Loss:  0.0000\n",
      "Accuracy: 89.40092165898618%\n",
      "Training epoch 26...\n",
      "Loss:  0.0000\n",
      "Accuracy: 89.51612903225806%\n",
      "Training epoch 27...\n",
      "Loss:  0.0000\n",
      "Accuracy: 89.51612903225806%\n",
      "Training epoch 28...\n",
      "Loss:  0.0000\n",
      "Accuracy: 89.51612903225806%\n",
      "Training epoch 29...\n",
      "Loss:  0.0000\n",
      "Accuracy: 89.51612903225806%\n",
      "Training epoch 30...\n",
      "Loss:  0.0000\n",
      "Accuracy: 89.57373271889401%\n",
      "Training epoch 31...\n",
      "Loss:  0.0000\n",
      "Accuracy: 89.45852534562212%\n",
      "Training epoch 32...\n",
      "Loss:  0.0000\n",
      "Accuracy: 89.51612903225806%\n",
      "Training epoch 33...\n",
      "Loss:  0.0000\n",
      "Accuracy: 89.57373271889401%\n",
      "Training epoch 34...\n",
      "Loss:  0.0000\n",
      "Accuracy: 89.51612903225806%\n",
      "Training epoch 35...\n",
      "Loss:  0.0000\n",
      "Accuracy: 89.51612903225806%\n",
      "Training epoch 36...\n",
      "Loss:  0.0000\n",
      "Accuracy: 89.51612903225806%\n",
      "Training epoch 37...\n",
      "Loss:  0.0000\n",
      "Accuracy: 89.57373271889401%\n",
      "Training epoch 38...\n",
      "Loss:  0.0000\n",
      "Accuracy: 89.57373271889401%\n",
      "Training epoch 39...\n",
      "Loss:  0.0000\n",
      "Accuracy: 89.57373271889401%\n",
      "Training epoch 40...\n",
      "Loss:  0.0000\n",
      "Accuracy: 89.63133640552995%\n",
      "Training epoch 41...\n",
      "Loss:  0.0000\n",
      "Accuracy: 89.57373271889401%\n",
      "Training epoch 42...\n",
      "Loss:  0.0000\n",
      "Accuracy: 89.51612903225806%\n",
      "Training epoch 43...\n",
      "Loss:  0.0000\n",
      "Accuracy: 89.57373271889401%\n",
      "Training epoch 44...\n",
      "Loss:  0.0000\n",
      "Accuracy: 89.57373271889401%\n",
      "Training epoch 45...\n",
      "Loss:  0.0000\n",
      "Accuracy: 89.57373271889401%\n",
      "Training epoch 46...\n",
      "Loss:  0.0000\n",
      "Accuracy: 89.57373271889401%\n",
      "Training epoch 47...\n",
      "Loss:  0.0000\n",
      "Accuracy: 89.57373271889401%\n",
      "Training epoch 48...\n",
      "Loss:  0.0000\n",
      "Accuracy: 89.57373271889401%\n",
      "Training epoch 49...\n",
      "Loss:  0.0000\n",
      "Accuracy: 89.57373271889401%\n",
      "Training epoch 50...\n",
      "Loss:  0.0000\n",
      "Accuracy: 89.57373271889401%\n",
      "Training epoch 51...\n",
      "Loss:  0.0000\n",
      "Accuracy: 89.57373271889401%\n",
      "Training epoch 52...\n",
      "Loss:  0.0000\n",
      "Accuracy: 89.57373271889401%\n",
      "Training epoch 53...\n",
      "Loss:  0.0000\n",
      "Accuracy: 89.57373271889401%\n",
      "Training epoch 54...\n",
      "Loss:  0.0000\n",
      "Accuracy: 89.57373271889401%\n",
      "Training epoch 55...\n",
      "Loss:  0.0000\n",
      "Accuracy: 89.57373271889401%\n",
      "Training epoch 56...\n",
      "Loss:  0.0000\n",
      "Accuracy: 89.57373271889401%\n",
      "Training epoch 57...\n",
      "Loss:  0.0000\n",
      "Accuracy: 89.57373271889401%\n",
      "Training epoch 58...\n",
      "Loss:  0.0000\n",
      "Accuracy: 89.57373271889401%\n",
      "Training epoch 59...\n",
      "Loss:  0.0000\n",
      "Accuracy: 89.57373271889401%\n"
     ]
    }
   ],
   "source": [
    "best=0\n",
    "EPOCH=60\n",
    "for epoch in range(EPOCH):\n",
    "    print(f'Training epoch {epoch}...')\n",
    "\n",
    "    train()\n",
    "\n",
    "    last=test(best)\n",
    "    if best < last:\n",
    "        best=last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_defult=DataProcess(label_file=\"./dataset/default/labels/VALIDATE.csv\",img_dir=\"./dataset/default/VALIDATE/\",transform=transform)\n",
    "validate_defult_loader= torch.utils.data.DataLoader(validate_defult, batch_size=10, shuffle=False, num_workers=0)\n",
    "validate_no_bg=DataProcess(label_file=\"./dataset/no_bg/labels/VALIDATE.csv\",img_dir=\"./dataset/no_bg/VALIDATE/\",transform=transform)\n",
    "validate_no_bg_loader= torch.utils.data.DataLoader(validate_no_bg, batch_size=10, shuffle=False, num_workers=0)\n",
    "validate_random_bg=DataProcess(label_file=\"./dataset/random_bg/labels/VALIDATE.csv\",img_dir=\"./dataset/random_bg/VALIDATE/\",transform=transform)\n",
    "validate_random_bg_loader= torch.utils.data.DataLoader(validate_random_bg, batch_size=10, shuffle=False, num_workers=0)\n",
    "\n",
    "validate_loaders=[validate_defult_loader,validate_no_bg_loader,validate_random_bg_loader]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(loader: torch.utils.data.DataLoader):\n",
    "    validate_model = NeuralNetV3()\n",
    "    validate_model.to(device)\n",
    "    validate_model.load_state_dict(torch.load(\"./models/self_train/default_best_3_0.pt\", weights_only=True))\n",
    "    validate_model.eval()\n",
    "    total=0\n",
    "    correct=0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            image, label =data\n",
    "            image, label = image.to(device), label.to(device)\n",
    "            outputs=validate_model(image)\n",
    "            _, predicts = torch.max(outputs, 1)\n",
    "\n",
    "            total += label.size(0)\n",
    "\n",
    "            correct += (predicts==label).sum().item()\n",
    "        \n",
    "        accuracy = 100*correct/total\n",
    "        print(f'Accuracy: {accuracy: .4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  90.6343\n",
      "Accuracy:  33.1354\n",
      "Accuracy:  44.0383\n"
     ]
    }
   ],
   "source": [
    "for loader in validate_loaders:\n",
    "    validate(loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
